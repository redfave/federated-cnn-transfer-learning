{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -r requirements.txt\n",
    "# ! pre-commit install\n",
    "# ! pre-commit run --all-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script .\\VGG_transfer_learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "def configure_logging(mode: Literal[\"a\", \"w\"]) -> logging.Logger:\n",
    "    if hasattr(__builtins__, \"__IPYTHON__\"):  # execution in Jupyter\n",
    "        sys.stdout = io.TextIOWrapper(sys.stdout, encoding=\"utf-8\")\n",
    "    else:  # execution in CPython\n",
    "        sys.stdout.reconfigure(encoding=\"utf-8\")  # type: ignore\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(threadName)s %(processName)s %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(\n",
    "                filename=f\"veggie-net.log\", mode=mode, encoding=\"utf-8\"\n",
    "            ),\n",
    "            logging.StreamHandler(),\n",
    "        ],\n",
    "    )\n",
    "    return logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disablePILDecompressionBombError() -> None:\n",
    "    from PIL import Image, ImageFile\n",
    "\n",
    "    Image.MAX_IMAGE_PIXELS = None  # Prevents PIL DecompressionBombError\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be here at top as on Windows the function is otherwise non pickleable\n",
    "def worker_init_fn(worker_id: int) -> None:\n",
    "    disablePILDecompressionBombError()\n",
    "    logger = configure_logging(\"a\")\n",
    "    logger.info(f\"Initialized worker {worker_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging before any torch module is imported\n",
    "logger = configure_logging(\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\falku\\My Drive\\Studium\\Master\\6. Semester\\Applied AI\\Assignment\\.venv-laptop-win\\Lib\\site-packages\\ignite\\handlers\\checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_directml\n",
    "from ignite.metrics import Accuracy, Fbeta, Precision, Recall\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, RandomSampler, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import VGG, VGG19_Weights, vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 12\n",
    "TARGET_SET = \"Original dataset\"  # target folder inside dataset (archive.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x264bdc58af0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_seed = np.random.randint(2141403747)\n",
    "random.seed(custom_seed)  # apparently seed must be set at several places\n",
    "torch.manual_seed(custom_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_device() -> torch.device:\n",
    "    return (\n",
    "        torch.device(\"cuda\")\n",
    "        if torch.cuda.is_available()\n",
    "        else torch_directml.device(torch_directml.default_device())\n",
    "        if torch_directml.is_available()\n",
    "        else torch.device(\"cpu\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='privateuseone', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = configure_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = ImageFolder(\n",
    "    root=os.path.join(\".\", \"archive\", TARGET_SET),\n",
    "    transform=VGG19_Weights.IMAGENET1K_V1.transforms(),  # Img inference transformation piepeline: https://pytorch.org/vision/main/models/generated/torchvision.models.vgg19.html\n",
    ")\n",
    "\n",
    "data_sets = SimpleNamespace(\n",
    "    **dict(\n",
    "        zip(\n",
    "            [\"train\", \"validation\", \"test\"],\n",
    "            random_split(dataset=dataset_full, lengths=[0.6, 0.3, 0.1]),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data_loader_kwargs = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"persistent_workers\": True,\n",
    "    # \"num_workers\": max(\n",
    "    #     2, (os.cpu_count() or 0) // 2\n",
    "    # ),  # too many workers may cause python to crash because of RAM usage\n",
    "    \"num_workers\": 8,\n",
    "    \"shuffle\": True,\n",
    "    # \"in_order\": False, # Only introduced in PyTorch v2.6\n",
    "    \"drop_last\": True,\n",
    "    \"worker_init_fn\": worker_init_fn,\n",
    "}\n",
    "\n",
    "if \"cuda\" in device.type.lower():\n",
    "    data_loader_kwargs | {\"pin_memory\": True, \"pin_memory_device\": device.type}\n",
    "\n",
    "\n",
    "data_loaders = SimpleNamespace(\n",
    "    train=DataLoader(data_sets.train, **data_loader_kwargs),\n",
    "    validation=DataLoader(data_sets.validation, **data_loader_kwargs),\n",
    "    test=DataLoader(data_sets.test, **data_loader_kwargs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_model(device) -> VGG:\n",
    "    model = vgg19(\n",
    "        weights=VGG19_Weights.DEFAULT\n",
    "    )  # model initialization with pretrained default weights\n",
    "\n",
    "    logger.info(\"MODEL INIT INFO:\")\n",
    "    logger.info(summary(model))  # use torchinfo for parameter info\n",
    "\n",
    "    model.features.requires_grad_(False)  # freeze all the blocks of model\n",
    "    model.avgpool.requires_grad_(False)\n",
    "    model.classifier.requires_grad_(False)\n",
    "\n",
    "    model.classifier[-1] = nn.Linear(\n",
    "        in_features=4096, out_features=6, bias=True\n",
    "    )  # replace the last classification layer\n",
    "    model.classifier[-1].requires_grad_(True)  # unfreeze new classification layer\n",
    "\n",
    "    logger.info(\"MODEL MODIFIED INFO:\")\n",
    "    logger.info(summary(model))  # most params should be non trainable\n",
    "\n",
    "    model = model.to(device)  # send model with forzen layers (hopefully) to GPU\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 00:06:17,169 [INFO] MainThread MainProcess MODEL INIT INFO:\n",
      "2025-02-17 00:06:17,175 [INFO] MainThread MainProcess =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "VGG                                      --\n",
      "├─Sequential: 1-1                        --\n",
      "│    └─Conv2d: 2-1                       1,792\n",
      "│    └─ReLU: 2-2                         --\n",
      "│    └─Conv2d: 2-3                       36,928\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─MaxPool2d: 2-5                    --\n",
      "│    └─Conv2d: 2-6                       73,856\n",
      "│    └─ReLU: 2-7                         --\n",
      "│    └─Conv2d: 2-8                       147,584\n",
      "│    └─ReLU: 2-9                         --\n",
      "│    └─MaxPool2d: 2-10                   --\n",
      "│    └─Conv2d: 2-11                      295,168\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Conv2d: 2-13                      590,080\n",
      "│    └─ReLU: 2-14                        --\n",
      "│    └─Conv2d: 2-15                      590,080\n",
      "│    └─ReLU: 2-16                        --\n",
      "│    └─Conv2d: 2-17                      590,080\n",
      "│    └─ReLU: 2-18                        --\n",
      "│    └─MaxPool2d: 2-19                   --\n",
      "│    └─Conv2d: 2-20                      1,180,160\n",
      "│    └─ReLU: 2-21                        --\n",
      "│    └─Conv2d: 2-22                      2,359,808\n",
      "│    └─ReLU: 2-23                        --\n",
      "│    └─Conv2d: 2-24                      2,359,808\n",
      "│    └─ReLU: 2-25                        --\n",
      "│    └─Conv2d: 2-26                      2,359,808\n",
      "│    └─ReLU: 2-27                        --\n",
      "│    └─MaxPool2d: 2-28                   --\n",
      "│    └─Conv2d: 2-29                      2,359,808\n",
      "│    └─ReLU: 2-30                        --\n",
      "│    └─Conv2d: 2-31                      2,359,808\n",
      "│    └─ReLU: 2-32                        --\n",
      "│    └─Conv2d: 2-33                      2,359,808\n",
      "│    └─ReLU: 2-34                        --\n",
      "│    └─Conv2d: 2-35                      2,359,808\n",
      "│    └─ReLU: 2-36                        --\n",
      "│    └─MaxPool2d: 2-37                   --\n",
      "├─AdaptiveAvgPool2d: 1-2                 --\n",
      "├─Sequential: 1-3                        --\n",
      "│    └─Linear: 2-38                      102,764,544\n",
      "│    └─ReLU: 2-39                        --\n",
      "│    └─Dropout: 2-40                     --\n",
      "│    └─Linear: 2-41                      16,781,312\n",
      "│    └─ReLU: 2-42                        --\n",
      "│    └─Dropout: 2-43                     --\n",
      "│    └─Linear: 2-44                      4,097,000\n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "2025-02-17 00:06:17,180 [INFO] MainThread MainProcess MODEL MODIFIED INFO:\n",
      "2025-02-17 00:06:17,186 [INFO] MainThread MainProcess =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "VGG                                      --\n",
      "├─Sequential: 1-1                        --\n",
      "│    └─Conv2d: 2-1                       (1,792)\n",
      "│    └─ReLU: 2-2                         --\n",
      "│    └─Conv2d: 2-3                       (36,928)\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─MaxPool2d: 2-5                    --\n",
      "│    └─Conv2d: 2-6                       (73,856)\n",
      "│    └─ReLU: 2-7                         --\n",
      "│    └─Conv2d: 2-8                       (147,584)\n",
      "│    └─ReLU: 2-9                         --\n",
      "│    └─MaxPool2d: 2-10                   --\n",
      "│    └─Conv2d: 2-11                      (295,168)\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Conv2d: 2-13                      (590,080)\n",
      "│    └─ReLU: 2-14                        --\n",
      "│    └─Conv2d: 2-15                      (590,080)\n",
      "│    └─ReLU: 2-16                        --\n",
      "│    └─Conv2d: 2-17                      (590,080)\n",
      "│    └─ReLU: 2-18                        --\n",
      "│    └─MaxPool2d: 2-19                   --\n",
      "│    └─Conv2d: 2-20                      (1,180,160)\n",
      "│    └─ReLU: 2-21                        --\n",
      "│    └─Conv2d: 2-22                      (2,359,808)\n",
      "│    └─ReLU: 2-23                        --\n",
      "│    └─Conv2d: 2-24                      (2,359,808)\n",
      "│    └─ReLU: 2-25                        --\n",
      "│    └─Conv2d: 2-26                      (2,359,808)\n",
      "│    └─ReLU: 2-27                        --\n",
      "│    └─MaxPool2d: 2-28                   --\n",
      "│    └─Conv2d: 2-29                      (2,359,808)\n",
      "│    └─ReLU: 2-30                        --\n",
      "│    └─Conv2d: 2-31                      (2,359,808)\n",
      "│    └─ReLU: 2-32                        --\n",
      "│    └─Conv2d: 2-33                      (2,359,808)\n",
      "│    └─ReLU: 2-34                        --\n",
      "│    └─Conv2d: 2-35                      (2,359,808)\n",
      "│    └─ReLU: 2-36                        --\n",
      "│    └─MaxPool2d: 2-37                   --\n",
      "├─AdaptiveAvgPool2d: 1-2                 --\n",
      "├─Sequential: 1-3                        --\n",
      "│    └─Linear: 2-38                      (102,764,544)\n",
      "│    └─ReLU: 2-39                        --\n",
      "│    └─Dropout: 2-40                     --\n",
      "│    └─Linear: 2-41                      (16,781,312)\n",
      "│    └─ReLU: 2-42                        --\n",
      "│    └─Dropout: 2-43                     --\n",
      "│    └─Linear: 2-44                      24,582\n",
      "=================================================================\n",
      "Total params: 139,594,822\n",
      "Trainable params: 24,582\n",
      "Non-trainable params: 139,570,240\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "model = configure_model(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    filter(\n",
    "        lambda model_parameter: model_parameter.requires_grad, model.parameters()\n",
    "    ),  # optimize just the non frozen parameters\n",
    "    lr=0.001,  # start learning rate\n",
    "    momentum=0.9,\n",
    ")\n",
    "scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=10, gamma=0.1\n",
    ")  # adjust learning rate per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch: int, summary_writer: SummaryWriter) -> float:\n",
    "    logger.info(f\"Starting training epoch: {epoch}\")\n",
    "    running_loss_training = 0.0\n",
    "    last_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(data_loaders.train):\n",
    "        logger.debug(f\"iteration: {i}\\tepoch-test: {epoch}\")\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()  # zero the parameter gradients\n",
    "        outputs = model(inputs)  # Make predictions for this batch\n",
    "\n",
    "        loss = criterion(outputs, labels)  # Compute the loss and its gradients\n",
    "        loss.backward()  # backpropagation\n",
    "\n",
    "        optimizer.step()  # Adjust learning weights\n",
    "\n",
    "        running_loss_training += loss.item()\n",
    "\n",
    "        if i % BATCH_SIZE == 0:\n",
    "            last_loss = running_loss_training / (i + 1)  # loss per mini-batch\n",
    "            tb_x = epoch * len(data_loaders.train) + i + 1\n",
    "\n",
    "            summary_writer.add_scalar(\"Loss/train\", last_loss, tb_x)\n",
    "\n",
    "    scheduler.step()  # Adjust learning rate\n",
    "    summary_writer.flush()\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "summary_writer = SummaryWriter(log_dir=f\"runs/veggie_trainer_{timestamp}\")\n",
    "model_path_best_epoch = \"\"\n",
    "\n",
    "precision = Precision(device=device)\n",
    "recall = Recall(device=device)\n",
    "accuracy = Accuracy(device=device)\n",
    "f1 = Fbeta(beta=1.0, precision=precision, recall=recall, device=device)\n",
    "\n",
    "\n",
    "def train():\n",
    "    best_loss_validation = float(\"inf\")\n",
    "\n",
    "    for epoch in range(EPOCHS + 1):\n",
    "        model.train(True)\n",
    "        avg_loss_train = train_one_epoch(epoch, summary_writer)\n",
    "        running_loss_test = 0.0\n",
    "        avg_loss_validation = 0.0\n",
    "\n",
    "        model.eval()  # Set the model to evaluation mode, disabling dropout and using population statistics for batch normalization\n",
    "\n",
    "        logger.info(f\"Starting validation epoch: {epoch}\")\n",
    "        with (\n",
    "            torch.no_grad()\n",
    "        ):  # Disable gradient computation and reduce memory consumption.\n",
    "            for i, data in enumerate(data_loaders.validation):\n",
    "                logger.debug(f\"iteration: {i}\\tepoch-validation: {epoch}\")\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss_test += loss.item()\n",
    "\n",
    "                # Log the running loss averaged per batch\n",
    "                avg_loss_validation = running_loss_test / (i + 1)\n",
    "\n",
    "                precision.update((outputs, labels))\n",
    "                recall.update((outputs, labels))\n",
    "                accuracy.update((outputs, labels))\n",
    "                f1.update((outputs, labels))\n",
    "\n",
    "        logger.info(f\"LOSS train {avg_loss_train} vs. validation {avg_loss_validation}\")\n",
    "\n",
    "        summary_writer.add_scalar(\"Loss/validation\", avg_loss_validation, epoch + 1)\n",
    "        summary_writer.add_scalar(\n",
    "            \"Precision/validation\", precision.compute().mean().item(), epoch + 1\n",
    "        )\n",
    "        summary_writer.add_scalar(\n",
    "            \"Recall/validation\", recall.compute().mean().item(), epoch + 1\n",
    "        )\n",
    "        summary_writer.add_scalar(\"Accuracy/validation\", accuracy.compute(), epoch + 1)\n",
    "        summary_writer.add_scalar(\"F1/validation\", f1.compute(), epoch + 1)\n",
    "\n",
    "        precision.reset()\n",
    "        recall.reset()\n",
    "        accuracy.reset()\n",
    "        f1.reset()\n",
    "        summary_writer.flush()\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_loss_validation < best_loss_validation:\n",
    "            best_loss_validation = avg_loss_validation\n",
    "\n",
    "            global model_path_best_epoch\n",
    "            model_path_best_epoch = os.path.join(\n",
    "                \".\", f\"veggie-net-{timestamp}-{epoch}.pth\"\n",
    "            )\n",
    "            torch.save(model.state_dict(), model_path_best_epoch)\n",
    "\n",
    "            model_path_previous_epoch = os.path.join(\n",
    "                \".\", f\"veggie-net-{timestamp}-{epoch - 1}.pth\"\n",
    "            )\n",
    "            if os.path.exists(model_path_previous_epoch):\n",
    "                os.remove(model_path_previous_epoch)\n",
    "\n",
    "    logger.info(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    logger.info(\"Running test\")\n",
    "    running_loss_test = 0.0\n",
    "    avg_loss_test = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation and reduce memory consumption.\n",
    "        for i, data in enumerate(data_loaders.test):\n",
    "            logger.debug(rf\"iteration: {i}\\of final test\")\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss_test += loss.item()\n",
    "\n",
    "            avg_loss_test = running_loss_test / (i + 1)\n",
    "\n",
    "            precision.update((outputs, labels))\n",
    "            recall.update((outputs, labels))\n",
    "            accuracy.update((outputs, labels))\n",
    "            f1.update((outputs, labels))\n",
    "\n",
    "        summary_writer.add_scalar(\"Loss/test\", avg_loss_test, EPOCHS)\n",
    "        summary_writer.add_scalar(\n",
    "            \"Precision/test\", precision.compute().mean().item(), EPOCHS\n",
    "        )\n",
    "        summary_writer.add_scalar(\"Recall/test\", recall.compute().mean().item(), EPOCHS)\n",
    "        summary_writer.add_scalar(\"Accuracy/test\", accuracy.compute(), EPOCHS)\n",
    "        summary_writer.add_scalar(\"F1/test\", f1.compute(), EPOCHS)\n",
    "\n",
    "        precision.reset()\n",
    "        recall.reset()\n",
    "        accuracy.reset()\n",
    "        f1.reset()\n",
    "        summary_writer.flush()\n",
    "\n",
    "    logger.info(f\"LOSS test {avg_loss_test}\")\n",
    "    logger.info(\"Test complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if __name__ == \"__main__\":\n",
    "# train()\n",
    "# model.load_state_dict(torch.load(model_path_best_epoch, map_location=device)) # load best performing model (might be from a previous epoch)\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 00:34:42,571 [INFO] MainThread MainProcess MODEL INIT INFO:\n",
      "2025-02-17 00:34:42,582 [INFO] MainThread MainProcess =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "VGG                                      --\n",
      "├─Sequential: 1-1                        --\n",
      "│    └─Conv2d: 2-1                       1,792\n",
      "│    └─ReLU: 2-2                         --\n",
      "│    └─Conv2d: 2-3                       36,928\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─MaxPool2d: 2-5                    --\n",
      "│    └─Conv2d: 2-6                       73,856\n",
      "│    └─ReLU: 2-7                         --\n",
      "│    └─Conv2d: 2-8                       147,584\n",
      "│    └─ReLU: 2-9                         --\n",
      "│    └─MaxPool2d: 2-10                   --\n",
      "│    └─Conv2d: 2-11                      295,168\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Conv2d: 2-13                      590,080\n",
      "│    └─ReLU: 2-14                        --\n",
      "│    └─Conv2d: 2-15                      590,080\n",
      "│    └─ReLU: 2-16                        --\n",
      "│    └─Conv2d: 2-17                      590,080\n",
      "│    └─ReLU: 2-18                        --\n",
      "│    └─MaxPool2d: 2-19                   --\n",
      "│    └─Conv2d: 2-20                      1,180,160\n",
      "│    └─ReLU: 2-21                        --\n",
      "│    └─Conv2d: 2-22                      2,359,808\n",
      "│    └─ReLU: 2-23                        --\n",
      "│    └─Conv2d: 2-24                      2,359,808\n",
      "│    └─ReLU: 2-25                        --\n",
      "│    └─Conv2d: 2-26                      2,359,808\n",
      "│    └─ReLU: 2-27                        --\n",
      "│    └─MaxPool2d: 2-28                   --\n",
      "│    └─Conv2d: 2-29                      2,359,808\n",
      "│    └─ReLU: 2-30                        --\n",
      "│    └─Conv2d: 2-31                      2,359,808\n",
      "│    └─ReLU: 2-32                        --\n",
      "│    └─Conv2d: 2-33                      2,359,808\n",
      "│    └─ReLU: 2-34                        --\n",
      "│    └─Conv2d: 2-35                      2,359,808\n",
      "│    └─ReLU: 2-36                        --\n",
      "│    └─MaxPool2d: 2-37                   --\n",
      "├─AdaptiveAvgPool2d: 1-2                 --\n",
      "├─Sequential: 1-3                        --\n",
      "│    └─Linear: 2-38                      102,764,544\n",
      "│    └─ReLU: 2-39                        --\n",
      "│    └─Dropout: 2-40                     --\n",
      "│    └─Linear: 2-41                      16,781,312\n",
      "│    └─ReLU: 2-42                        --\n",
      "│    └─Dropout: 2-43                     --\n",
      "│    └─Linear: 2-44                      4,097,000\n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "2025-02-17 00:34:42,582 [INFO] MainThread MainProcess MODEL MODIFIED INFO:\n",
      "2025-02-17 00:34:42,582 [INFO] MainThread MainProcess =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "VGG                                      --\n",
      "├─Sequential: 1-1                        --\n",
      "│    └─Conv2d: 2-1                       (1,792)\n",
      "│    └─ReLU: 2-2                         --\n",
      "│    └─Conv2d: 2-3                       (36,928)\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─MaxPool2d: 2-5                    --\n",
      "│    └─Conv2d: 2-6                       (73,856)\n",
      "│    └─ReLU: 2-7                         --\n",
      "│    └─Conv2d: 2-8                       (147,584)\n",
      "│    └─ReLU: 2-9                         --\n",
      "│    └─MaxPool2d: 2-10                   --\n",
      "│    └─Conv2d: 2-11                      (295,168)\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Conv2d: 2-13                      (590,080)\n",
      "│    └─ReLU: 2-14                        --\n",
      "│    └─Conv2d: 2-15                      (590,080)\n",
      "│    └─ReLU: 2-16                        --\n",
      "│    └─Conv2d: 2-17                      (590,080)\n",
      "│    └─ReLU: 2-18                        --\n",
      "│    └─MaxPool2d: 2-19                   --\n",
      "│    └─Conv2d: 2-20                      (1,180,160)\n",
      "│    └─ReLU: 2-21                        --\n",
      "│    └─Conv2d: 2-22                      (2,359,808)\n",
      "│    └─ReLU: 2-23                        --\n",
      "│    └─Conv2d: 2-24                      (2,359,808)\n",
      "│    └─ReLU: 2-25                        --\n",
      "│    └─Conv2d: 2-26                      (2,359,808)\n",
      "│    └─ReLU: 2-27                        --\n",
      "│    └─MaxPool2d: 2-28                   --\n",
      "│    └─Conv2d: 2-29                      (2,359,808)\n",
      "│    └─ReLU: 2-30                        --\n",
      "│    └─Conv2d: 2-31                      (2,359,808)\n",
      "│    └─ReLU: 2-32                        --\n",
      "│    └─Conv2d: 2-33                      (2,359,808)\n",
      "│    └─ReLU: 2-34                        --\n",
      "│    └─Conv2d: 2-35                      (2,359,808)\n",
      "│    └─ReLU: 2-36                        --\n",
      "│    └─MaxPool2d: 2-37                   --\n",
      "├─AdaptiveAvgPool2d: 1-2                 --\n",
      "├─Sequential: 1-3                        --\n",
      "│    └─Linear: 2-38                      (102,764,544)\n",
      "│    └─ReLU: 2-39                        --\n",
      "│    └─Dropout: 2-40                     --\n",
      "│    └─Linear: 2-41                      (16,781,312)\n",
      "│    └─ReLU: 2-42                        --\n",
      "│    └─Dropout: 2-43                     --\n",
      "│    └─Linear: 2-44                      24,582\n",
      "=================================================================\n",
      "Total params: 139,594,822\n",
      "Trainable params: 24,582\n",
      "Non-trainable params: 139,570,240\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load a previously trained model manually\n",
    "device = configure_device()\n",
    "model = configure_model(device=device)\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        os.path.join(\".\", \"veggie-net-20250216_235626-1.pth\"), weights_only=False\n",
    "    )\n",
    ")\n",
    "model = model.to(device=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prediction: Eggplant | Actual Label: Eggplant'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual (visual) validation\n",
    "# from torchvision.transforms import ToPILImage\n",
    "# disablePILDecompressionBombError()\n",
    "\n",
    "# idx_to_class = {v: k for k, v in dataset_full.class_to_idx.items()}\n",
    "\n",
    "# sample, label = data_sets.validation[random.randint(0, len(data_sets.validation) - 1)]\n",
    "# sample_batch = sample.unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "# ToPILImage()(sample).show()\n",
    "# f\"Prediction: {idx_to_class[model(sample_batch).argmax().item()]} | Actual Label: {idx_to_class[label]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage: https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html\n",
    "# ! tensorboard --logdir=./runs/\n",
    "# go to http://localhost:6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-laptop-win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
